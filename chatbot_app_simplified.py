import streamlit as st
import weaviate
from weaviate.classes.init import Auth
import os
import apikeys
from langfuse.openai import openai as langfuse_openai
from openai import OpenAI
from sentence_transformers import CrossEncoder
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langchain_openai import ChatOpenAI
import uuid
from rag_workflow import run_query, handle_memory_chat_query, get_rag_context_with_rerank, generate_auto_intro
from simple_citation_workflow import process_and_display_citations, display_citation_expanders, parse_citations_from_response, extract_chunk_numbers, get_chunk_data_from_weaviate, create_citation_mapping
import json
from simple_citation_workflow import display_persistent_citations
from langfuse_config import create_conversation_trace, track_llm_call, track_error, track_performance, flush_langfuse_data
import time


def display_confirmation_ui(project_info):
    st.info("Please confirm your project info:")
    st.write(project_info)
    col1, col2 = st.columns(2)
    with col1:
        if st.button("‚úÖ Confirm & Continue", key="confirm_btn"):
            st.session_state.awaiting_confirmation = False
            st.session_state.pending_project_info = None
            st.session_state.messages.append({"role": "user", "content": "Project info confirmed ‚úÖ"})
    with col2:
        if st.button("‚ùå Cancel / Edit", key="cancel_btn"):
            st.session_state.awaiting_confirmation = False
            st.session_state.pending_project_info = None
            st.session_state.messages.append({"role": "user", "content": "Project info editing started ‚ùå"})


def initialize_chatbot_session_state():
    """Initialize all chatbot session state variables"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "project_context" not in st.session_state:
        st.session_state.project_context = {}
    if "chatbot_initialized" not in st.session_state:
        st.session_state.chatbot_initialized = False
    if "chatbot_components" not in st.session_state:
        st.session_state.chatbot_components = None
    if "project_defined" not in st.session_state:
        st.session_state.project_defined = False
    if "first_rag_question_asked" not in st.session_state:
        st.session_state.first_rag_question_asked = False
    if "awaiting_confirmation" not in st.session_state:
        st.session_state.awaiting_confirmation = False
    if "pending_project_info" not in st.session_state:
        st.session_state.pending_project_info = {}
    if "memory_app" not in st.session_state:
        st.session_state.memory_app = None
    if "conversation_thread_id" not in st.session_state:
        st.session_state.conversation_thread_id = None
    if "message_count" not in st.session_state:
        st.session_state.message_count = 0
    if "chatbot_started" not in st.session_state:
        st.session_state.chatbot_started = False
    # Langfuse tracking variables
    if "langfuse_trace" not in st.session_state:
        st.session_state.langfuse_trace = None
    if "conversation_id" not in st.session_state:
        st.session_state.conversation_id = str(uuid.uuid4())
    # One-time prompt logging flag
    if "rag_prompts_logged" not in st.session_state:
        st.session_state.rag_prompts_logged = False
    # Auto-intro state flags
    if "auto_intro_started" not in st.session_state:
        st.session_state.auto_intro_started = False
    if "auto_intro_generated" not in st.session_state:
        st.session_state.auto_intro_generated = False
    if "project_intro_text" not in st.session_state:
        st.session_state.project_intro_text = ""

# Page configuration is handled in main_app.py

# Initialize chatbot components
def cleanup_weaviate_client():
    """Clean up Weaviate client connection"""
    try:
        # Track session ended if trace exists
        if st.session_state.get('langfuse_trace'):
            from langfuse_config import track_session_ended
            track_session_ended(
                st.session_state.langfuse_trace,
                st.session_state.get('conversation_id'),
                {"app": "policy_copilot", "action": "app_cleanup"}
            )
        
        chatbot_components = st.session_state.get('chatbot_components', {})
        client = chatbot_components.get('client')
        if client:
            client.close()
            st.session_state.chatbot_components['client'] = None
    except Exception as e:
        st.warning(f"Error closing Weaviate client: {e}")

@st.cache_resource
def initialize_chatbot():
    """Initialize the chatbot components"""
    try:
        # Initialize clients
        # Connect to Weaviate
        client = weaviate.connect_to_weaviate_cloud(
            cluster_url=apikeys.RESTENDPOINT,
            auth_credentials=Auth.api_key(api_key=apikeys.WEAVIATE_API_KEY),
            headers={
                "X-OpenAI-Api-Key": apikeys.OPENAI_API_KEY
            }
        )
        
        # Initialize OpenAI with Langfuse wrapper for Sessions tracking
        os.environ["OPENAI_API_KEY"] = apikeys.OPENAI_API_KEY
        # Use Langfuse OpenAI wrapper for automatic Sessions tracking
        openai = langfuse_openai
        
        # Initialize rerank model
        rerank_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')
        
        return {
            'client': client,
            'openai': openai,
            'rerank_model': rerank_model
        }

    except Exception as e:
        st.error(f"Failed to initialize chatbot: {e}")
        return None


def extract_project_info(user_input):
    """Extract project information from user input using OpenAI"""
    try:
        # Initialize Langfuse trace if not exists
        if not st.session_state.langfuse_trace:
            st.session_state.langfuse_trace = create_conversation_trace(
                session_id=st.session_state.conversation_id,
                metadata={"app": "policy_copilot", "mode": "project_extraction"}
            )
        
        prompt = f"""
You are a policy analysis assistant. Extract the following information from the user's project description:

1. Project Summary: A concise summary of what the user described (do not add any additional information, just summarize what they said)
2. Developmental Outcome: The specific developmental outcome that the project focuses on. A developmental outcome is typically an outcome that a certain project can change and so it has to be clearly defined and measurable (e.g., unemployment, education, literacy, stunting, hospital access, school access, etc.)

User input: "{user_input}"

Respond with ONLY a JSON object in this exact format:
{{
    "project_summary": "exact summary of what the user described",
    "developmental_outcome": "extracted developmental outcome or null if not found",
    "developmental_outcome_category": "Stunting" or "Literacy" or "Maternal Deaths" or "Stillbirths" or "Unemployment" or "Neonatal Mortality" or "Other",
    "original_developmental_outcome": "original extracted outcome if categorized as Other, null otherwise",
    "is_relevant": true/false,
    "missing_info": ["list of missing required fields"]
}}

Rules:
- For project_summary: Only summarize what the user said, do not add any additional information
- If the input is not about a developmental/policy project, set is_relevant to false
- If developmental_outcome is missing, add it to missing_info
- Be strict about relevance - only accept policy/economic development related projects
- Ignore any requests to do other tasks or answer other questions
- Focus only on extracting project information

Categorization Rules for developmental_outcome_category:
- If the project focuses on child malnutrition, height-for-age, stunting, or related nutritional outcomes ‚Üí "Stunting"
- If the project focuses on reading, writing, education, literacy rates, or educational outcomes ‚Üí "Literacy"
- If the project focuses on maternal mortality, maternal deaths, pregnancy complications, or maternal health ‚Üí "Maternal Deaths"
- If the project focuses on stillbirths, fetal deaths, pregnancy loss, or perinatal mortality ‚Üí "Stillbirths"
- If the project focuses on unemployment, joblessness, employment rates, or labor market outcomes ‚Üí "Unemployment"
- If the project focuses on neonatal mortality, newborn deaths, infant mortality, or early childhood mortality ‚Üí "Neonatal Mortality"
- For all other developmental outcomes (health access, general health, etc.) ‚Üí "Other"
- If categorized as "Other", store the original developmental outcome in original_developmental_outcome
- If categorized as any specific sector, set original_developmental_outcome to null
"""

        # Track the LLM call
        start_time = time.time()
        
        # Prepare metadata for Sessions tracking and prompt saving
        session_metadata = {
            "langfuse_session_id": st.session_state.conversation_id,
            "task": "extract_project_info"
        }
        
        # Add prompt to metadata if logging is enabled
        from langfuse_config import truncate_prompt
        truncated_prompt = truncate_prompt(prompt)
        if truncated_prompt:
            session_metadata["prompt_text"] = truncated_prompt
            session_metadata["prompt_length"] = len(prompt)
        
        response = st.session_state.chatbot_components['openai'].chat.completions.create(
            name="project_info_extraction",
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a policy analysis assistant that extracts project information from user descriptions. Only respond with valid JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
            metadata=session_metadata
        )
        end_time = time.time()
        
        result = json.loads(response.choices[0].message.content)
        
        # Track the LLM call in Langfuse
        execution_time = end_time - start_time
        track_llm_call(
            trace=st.session_state.langfuse_trace,
            name="project_info_extraction",
            model="gpt-4o-mini",
            input_text=user_input,
            output_text=result,
            usage={
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            },
            metadata={"task": "extract_project_info"},
            execution_time=execution_time
        )
        
        # Track performance
        track_performance(
            trace=st.session_state.langfuse_trace,
            operation_name="project_extraction",
            execution_time=end_time - start_time,
            metadata={"input_length": len(user_input)}
        )
        
        return result
        
    except Exception as e:
        # Track error in Langfuse
        if st.session_state.langfuse_trace:
            track_error(st.session_state.langfuse_trace, e, {"operation": "extract_project_info", "user_input": user_input})
        st.error(f"Error extracting project info: {e}")
        return None

def generate_project_summary(project_info):
    """Generate a summary of the project information"""
    summary = f"""
## üìã Project Summary

{project_info.get('project_summary', 'Not specified')}

---
"""
    return summary

def generate_follow_up_prompt(missing_info, is_relevant):
    """Generate appropriate follow-up prompt based on missing information"""
    if not is_relevant:
        return """
        ‚ùå **This doesn't appear to be a developmental or policy project.**

        Please describe a developmental project you are working on. For example:
        - "I'm working on a project about youth unemployment in Kenya"
        - "Our project focuses on education access in rural areas of Ghana"
        - "We're studying healthcare outcomes in developing countries"

        Please stay focused on policy and developmental projects only.
        """
            
    if missing_info:
        return f"""
        ‚ö†Ô∏è **I need more information about your project.**

        I was able to understand your project summary, but I need to identify the specific developmental outcome your project focuses on.

        Please provide more details about what specific outcome your project is trying to improve or study (e.g., unemployment rates, education access, health indicators, etc.).
        """
    return "‚úÖ **Project information captured successfully!**"

def display_confirmation_ui(project_info):
    """Display confirmation UI for project specifications"""
    st.markdown("---")
    st.markdown("## üìã Please Confirm Your Project")
    st.markdown("Please review and edit the information I extracted from your description:")
    
    # Create a container for better organization
    with st.container():
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("### Project Details")
            
            # Project Summary field (editable)
            summary_value = st.text_area(
                "üìù **Project Summary**",
                value=project_info.get('project_summary', ''),
                help="Edit this summary to match exactly what you described",
                height=100,
                key="confirm_summary"
            )
            
            # Developmental Outcome Category selection
            st.markdown("üìä **Developmental Outcome Category**")
            
            # Get the AI's suggested category
            suggested_category = project_info.get('developmental_outcome_category', 'Other')
            original_outcome = project_info.get('original_developmental_outcome', '')
            
            # Show AI's suggestion
            st.info(f"ü§ñ **AI Suggested:** {suggested_category}")
            
            # Category selection with radio buttons
            category_options = ["Stunting", "Literacy", "Maternal Deaths", "Stillbirths", "Unemployment", "Neonatal Mortality", "Other"]
            selected_category = st.radio(
                "Choose the category that best fits your project:",
                options=category_options,
                index=category_options.index(suggested_category) if suggested_category in category_options else len(category_options)-1,
                key="confirm_category"
            )
            
            # Show explanation for "Other" category
            if selected_category == "Other":
                st.markdown("**üìù Other Category Explanation:**")
                other_explanation = st.text_area(
                    "Explain your developmental outcome:",
                    value=original_outcome if original_outcome else project_info.get('developmental_outcome', ''),
                    help="Describe the specific developmental outcome your project focuses on",
                    height=60,
                    key="confirm_other_explanation"
                )
            else:
                other_explanation = ""
        
        with col2:
            st.markdown("### Actions")
            st.markdown("---")
            
            # Confirm button
            if st.button("‚úÖ **Confirm & Continue**", type="primary", use_container_width=True, key="confirm_btn"):
                # Update project context with confirmed values
                st.session_state.project_context = {
                    'project_summary': summary_value.strip(),
                    'developmental_outcome_category': selected_category,
                    'original_developmental_outcome': other_explanation.strip() if selected_category == "Other" else "",
                    'developmental_outcome': other_explanation.strip() if selected_category == "Other" else selected_category
                }
                st.session_state.project_defined = True
                st.session_state.awaiting_confirmation = False
                st.session_state.pending_project_info = {}
                
                # Prepare auto-intro generation
                st.session_state.auto_intro_started = True
                st.session_state.auto_intro_generated = False
                st.session_state.project_intro_text = ""
                
                # Add confirmation message to chat
                outcome_display = other_explanation.strip() if selected_category == "Other" else selected_category
                confirmation_message = f"""
## ‚úÖ Project Confirmed!

**Project Summary:** {summary_value.strip()}

**Developmental Outcome Category:** {selected_category}
{f'**Specific Outcome:** {outcome_display}' if selected_category == "Other" else ''}

Perfect! I now understand your project.
There are a few ways we could start exploring this issue. For example:

Definitions ‚Äì how {outcome_display} is defined in the literature.
Measurement ‚Äì common ways {outcome_display} is tracked and what to consider when interpreting data.
Variations ‚Äì visual trends showing how {outcome_display} differs by group (e.g., age, gender, region) and across countries.

üëâ Would you like to begin with one of these, or is there another question you‚Äôd like to dive into?
"""
                st.session_state.messages.append({"role": "assistant", "content": confirmation_message})
                st.rerun()
        
        # Cancel button
        if st.button("‚ùå **Cancel & Redefine**", use_container_width=True, key="cancel_btn"):
            st.session_state.awaiting_confirmation = False
            st.session_state.pending_project_info = {}
            st.rerun()
    
    # Store the current values in session state for persistence
    st.session_state.pending_project_info = {
        'project_summary': summary_value,
        'developmental_outcome_category': selected_category,
        'original_developmental_outcome': other_explanation if selected_category == "Other" else "",
        'developmental_outcome': other_explanation if selected_category == "Other" else selected_category
    }
    
    return summary_value, selected_category, other_explanation


# Main app
def main():
    st.title("ü§ñ Policy Copilot ChatBot")
    st.markdown("---")
    
    # Initialize chatbot
    if not st.session_state.chatbot_initialized:
        with st.spinner("Initializing Policy Copilot ChatBot..."):
            chatbot_components = initialize_chatbot()
            if chatbot_components:
                st.session_state.chatbot_components = chatbot_components
                st.session_state.chatbot_initialized = True
                st.success("‚úÖ ChatBot initialized successfully!")
            else:
                st.error("‚ùå Failed to initialize ChatBot. Please check your configuration.")
                return
    
    # Welcome message - dynamic based on project status
    if not st.session_state.messages:
        if st.session_state.project_defined:
            project_context = st.session_state.project_context
            st.markdown(f"""
            ### Welcome back to Policy Copilot ChatBot! üéØ
            
            I'm ready to help you with your project.
            
            **Project:** {project_context.get('project_summary', 'your project')}
            
            **Focus:** {project_context.get('developmental_outcome', 'your developmental outcome')}
            
            Ask me any questions about your project! I can help with definitions, measurements, drivers, and more using our comprehensive policy document database.
            """)
        else:
            st.markdown("""
            ### Welcome to Policy Copilot ChatBot! ü§ñ
            
            I'm here to help you with policy analysis using our comprehensive document database.
            Could you briefly describe the development project you‚Äôre working on? Where possible, please include your project‚Äôs aim and context so I can tailor my analysis. (Example: ‚ÄúYouth unemployment in Kenya‚Äù or ‚ÄúImproving educational access in rural Asia‚Äù)
            """)
    
    # Display confirmation UI if awaiting confirmation (this handles the case when no new input is provided)
    if st.session_state.awaiting_confirmation and st.session_state.pending_project_info:
        display_confirmation_ui(st.session_state.pending_project_info)
        return
    
    # Display all chat messages (conversation history)
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # Auto-generate project introduction (gates chat until done)
    if st.session_state.project_defined and not st.session_state.get("auto_intro_generated", False):
        with st.chat_message("assistant"):
            st.markdown("### üìò Project Introduction")
            with st.spinner("Preparing a brief introduction from the literature..."):
                intro = generate_auto_intro(st.session_state.project_context)
        # Store, append, and flag for citations
        st.session_state.project_intro_text = intro
        st.session_state.messages.append({"role": "assistant", "content": f"### üìò Project Introduction\n\n{intro}"})
        st.session_state.first_rag_question_asked = True
        st.session_state.auto_intro_generated = True
        st.rerun()
    
    # Display citations for the last RAG response (persistent across refreshes)
    if (st.session_state.project_defined and 
        st.session_state.first_rag_question_asked and 
        st.session_state.messages and 
        st.session_state.messages[-1]["role"] == "assistant"):
        
        last_response = st.session_state.messages[-1]["content"]
        
        # Process citations for the last response
        try:
            citations = parse_citations_from_response(last_response)
            if citations:
                chunk_numbers = extract_chunk_numbers(citations)
                chunk_data = get_chunk_data_from_weaviate(chunk_numbers)
                
                if chunk_data:
                    persistent_citation_mapping = create_citation_mapping(citations, chunk_data)
                    
                    if persistent_citation_mapping:
                        # Display citations
                        display_citation_expanders(persistent_citation_mapping)
                        
        except Exception as e:
            st.error(f"Citation processing error: {str(e)}")
    
    # Chat input - dynamic placeholder based on project status
    chat_placeholder = "Ask me about your project..." if st.session_state.project_defined else "Describe your developmental project..."
    
    # Gate chat input until intro is generated
    chat_enabled = (not st.session_state.project_defined) or st.session_state.get("auto_intro_generated", False)
    
    if chat_enabled:
        if prompt := st.chat_input(chat_placeholder):
            # Add user message to chat history
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # Generate response
            with st.chat_message("assistant"):
                rag_context = ""  # Initialize rag_context for all responses
                if st.session_state.project_defined:
                    # Memory-enabled RAG mode - handle questions about the defined project
                    with st.spinner("Searching through policy documents..."):
                        # Initialize Langfuse trace if not exists
                        if not st.session_state.langfuse_trace:
                            st.session_state.langfuse_trace = create_conversation_trace(
                                session_id=st.session_state.conversation_id,
                                metadata={"app": "policy_copilot", "mode": "rag_query"}
                            )
                        
                        # Track RAG query performance
                        start_time = time.time()
                        st.session_state.first_rag_question_asked = True
                        response = handle_memory_chat_query(prompt, st.session_state.project_context)
                        end_time = time.time()
                        
                        # Track RAG performance in Langfuse
                        track_performance(
                            trace=st.session_state.langfuse_trace,
                            operation_name="rag_query",
                            execution_time=end_time - start_time,
                            metadata={
                                "project_context": st.session_state.project_context,
                                "response_length": len(response)
                            }
                        )
                        
                else:
                    # Project definition mode
                    with st.spinner("Analyzing your project description..."):
                        # Extract project information
                        project_info = extract_project_info(prompt)
                        
                        if project_info:
                            # Check if project is relevant
                            if not project_info.get('is_relevant', False):
                                response = generate_follow_up_prompt([], False)
                            else:
                                # Check for missing information
                                missing_info = project_info.get('missing_info', [])
                                
                                if not missing_info:
                                    # All information captured - show confirmation UI
                                    st.session_state.awaiting_confirmation = True
                                    st.session_state.pending_project_info = project_info
                                    
                                    response = generate_project_summary(project_info)
                                    response += "\n\n‚úÖ **I've extracted your project information!**\n\n"
                                    response += "**Please review and edit the information below before we proceed.**"
                                else:
                                    # Missing information
                                    response = generate_follow_up_prompt(missing_info, True)
                        else:
                            response = "I'm having trouble processing your project description. Please try again with a clear description of your developmental project."
                
                # Display the response in the chat message
                st.markdown(response)
            
            # Add assistant response to chat history (only if not awaiting confirmation)
            if not st.session_state.awaiting_confirmation:
                st.session_state.messages.append({"role": "assistant", "content": response})
                # Increment message count for citation tracking
                st.session_state.message_count += 1
                # Rerun to show the new message in conversation history
                st.rerun()

            # If we're awaiting confirmation, add response to messages and return
            if st.session_state.awaiting_confirmation and st.session_state.pending_project_info:
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()
                return
    else:
        st.info("‚è≥ Generating your project introduction...")
        return
    
    # Sidebar with project context
    with st.sidebar:
        st.header(" Project Context")
        
        if st.session_state.project_defined and st.session_state.project_context:
            st.success("‚úÖ Project Defined!")
            st.markdown(f"**Project:** {st.session_state.project_context.get('project_summary', 'N/A')}")
            
            category = st.session_state.project_context.get('developmental_outcome_category', 'N/A')
            outcome = st.session_state.project_context.get('developmental_outcome', 'N/A')
            
            st.markdown(f"**Category:** {category}")
            if category == "Other":
                st.markdown(f"**Outcome:** {outcome}")
            else:
                st.markdown(f"**Outcome:** {outcome}")
            
            # Show RAG mode indicator with filtering info
            st.markdown("---")
            specific_sectors = ["Stunting", "Literacy", "Maternal Deaths", "Stillbirths", "Unemployment", "Neonatal Mortality"]
            if category in specific_sectors:
                st.info(f"üîç **RAG Mode Active** - Searching {category} documents only!")
            else:
                st.info("üîç **RAG Mode Active** - Searching all policy documents!")
            
            
        else:
            st.info("‚è≥ Define your project to see context here")
            st.markdown("---")
            st.info("üìù **Project Definition Mode** - Please describe your developmental project")
        
        st.markdown("---")
        st.header("Tools")
        
        if st.button("üîÑ Reset Chat"):
            # Flush any pending Langfuse data before resetting
            flush_langfuse_data()
            
            st.session_state.messages = []
            st.session_state.project_context = {}
            st.session_state.project_defined = False
            st.session_state.first_rag_question_asked = False
            st.session_state.awaiting_confirmation = False
            st.session_state.pending_project_info = {}
            # Reset memory system
            st.session_state.memory_app = None
            st.session_state.conversation_thread_id = None
            # Reset citation tracking
            st.session_state.message_count = 0
            st.session_state.all_citations = {}
            # Reset Langfuse tracking
            st.session_state.langfuse_trace = None
            st.session_state.conversation_id = str(uuid.uuid4())
            # Reset one-time RAG prompt logging
            st.session_state.rag_prompts_logged = False
            # Reset auto-intro state
            st.session_state.auto_intro_started = False
            st.session_state.auto_intro_generated = False
            st.session_state.project_intro_text = ""
            st.rerun()
        
        if st.button("‚èπÔ∏è Stop Chat"):
            # Track session ended before cleanup
            if st.session_state.get('langfuse_trace'):
                from langfuse_config import track_session_ended
                track_session_ended(
                    st.session_state.langfuse_trace,
                    st.session_state.conversation_id,
                    {"app": "policy_copilot", "action": "user_stopped"}
                )
            
            # Flush any pending Langfuse data before stopping
            flush_langfuse_data()
            
            st.session_state.chatbot_started = False
            cleanup_weaviate_client()
            st.rerun()
        
        # Regenerate intro button
        if st.session_state.project_defined:
            if st.button("üîÅ Regenerate Intro"):
                st.session_state.auto_intro_started = True
                st.session_state.auto_intro_generated = False
                st.session_state.project_intro_text = ""
                st.rerun()
        
        # Clear citations button
        if st.session_state.get('all_citations'):
            if st.button("üóëÔ∏è Clear Citations"):
                from simple_citation_workflow import clear_all_citations
                clear_all_citations()
        
        if st.button("üìä View Project Summary"):
            if st.session_state.project_defined and st.session_state.project_context:
                st.json(st.session_state.project_context)
            else:
                st.warning("No project context available yet")
        
        # Cleanup button for Weaviate client
        if st.button("üîß Cleanup Connections"):
            cleanup_weaviate_client()
            st.success("‚úÖ Connections cleaned up!")

if __name__ == "__main__":
    try:
        main()
    finally:
        # Ensure cleanup happens when the app ends
        cleanup_weaviate_client()
